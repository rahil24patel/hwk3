{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6300f3f2-17ce-45f0-8f94-9812ad1caf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MA_ROOT : /scion/5261/econ470001/ma-data/ma\n",
      "OUTPUT  : /home/rpat638/econ470/a0/work/hwk3/data/output\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('display.width', 220)\n",
    "\n",
    "YEARS = list(range(2010, 2016))\n",
    "\n",
    "HWK3_ROOT  = Path.cwd()\n",
    "CACHE_DIR  = HWK3_ROOT / 'data' / 'cache'\n",
    "OUTPUT_DIR = HWK3_ROOT / 'data' / 'output'\n",
    "for d in [CACHE_DIR, OUTPUT_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "_CANDIDATES = [\n",
    "    Path('/scion/5261/econ470001/ma-data/ma'),\n",
    "    Path('/home/rpat638/econ470/a0/work/ma-data/ma'),\n",
    "    HWK3_ROOT.parent / 'ma-data' / 'ma',\n",
    "    HWK3_ROOT.parent.parent / 'ma-data' / 'ma',\n",
    "]\n",
    "\n",
    "def _pick(paths):\n",
    "    for p in paths:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError('No MA_ROOT found. Check _CANDIDATES:\\n' + '\\n'.join(str(p) for p in paths))\n",
    "\n",
    "MA_ROOT    = _pick(_CANDIDATES)\n",
    "ENROLL_DIR = MA_ROOT / 'enrollment'   / 'Extracted Data'\n",
    "SAREA_DIR  = MA_ROOT / 'service-area' / 'Extracted Data'\n",
    "PEN_DIR    = MA_ROOT / 'penetration'  / 'Extracted Data'\n",
    "STARS_DIR  = MA_ROOT / 'star-ratings' / 'Extracted Star Ratings'\n",
    "BENCH_DIR  = MA_ROOT / 'benchmarks'\n",
    "\n",
    "TERRITORIES = {'VI', 'PR', 'MP', 'GU', 'AS'}\n",
    "\n",
    "print('MA_ROOT :', MA_ROOT)\n",
    "print('OUTPUT  :', OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f8cdc46-5c55-496f-914b-650b90dd2a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RATING_VARS loaded for years: [2010, 2011, 2012, 2013, 2014, 2015]\n"
     ]
    }
   ],
   "source": [
    "RATING_VARS = {\n",
    "    2010: [\n",
    "        'contractid', 'org_type', 'contract_name', 'org_marketing',\n",
    "        'breastcancer_screen', 'rectalcancer_screen', 'cv_diab_cholscreen',\n",
    "        'glaucoma_test', 'monitoring', 'flu_vaccine', 'pn_vaccine',\n",
    "        'physical_health', 'mental_health', 'osteo_test', 'physical_monitor',\n",
    "        'primaryaccess', 'osteo_manage', 'diab_healthy', 'bloodpressure',\n",
    "        'ra_manage', 'copd_test', 'bladder', 'falling',\n",
    "        'nodelays', 'doctor_communicate', 'carequickly', 'customer_service',\n",
    "        'overallrating_care', 'overallrating_plan',\n",
    "        'complaints_plan', 'appeals_timely', 'appeals_review',\n",
    "        'leave_plan', 'audit_problems', 'hold_times', 'info_accuracy', 'ttyt_available',\n",
    "    ],\n",
    "    2011: [\n",
    "        'contractid', 'org_type', 'contract_name', 'org_marketing',\n",
    "        'breastcancer_screen', 'rectalcancer_screen', 'cv_cholscreen', 'diab_cholscreen',\n",
    "        'glaucoma_test', 'monitoring', 'flu_vaccine', 'pn_vaccine',\n",
    "        'physical_health', 'mental_health', 'osteo_test', 'physical_monitor',\n",
    "        'primaryaccess', 'osteo_manage',\n",
    "        'diabetes_eye', 'diabetes_kidney', 'diabetes_bloodsugar', 'diabetes_chol',\n",
    "        'bloodpressure', 'ra_manage', 'copd_test', 'bladder', 'falling',\n",
    "        'nodelays', 'doctor_communicate', 'carequickly', 'customer_service',\n",
    "        'overallrating_care', 'overallrating_plan',\n",
    "        'complaints_plan', 'appeals_timely', 'appeals_review',\n",
    "        'corrective_action', 'hold_times', 'info_accuracy', 'ttyt_available',\n",
    "    ],\n",
    "    2012: [\n",
    "        'contractid', 'org_type', 'org_parent', 'org_marketing',\n",
    "        'breastcancer_screen', 'rectalcancer_screen', 'cv_cholscreen', 'diab_cholscreen',\n",
    "        'glaucoma_test', 'flu_vaccine', 'pn_vaccine',\n",
    "        'physical_health', 'mental_health', 'physical_monitor',\n",
    "        'primaryaccess', 'bmi_assess',\n",
    "        'older_medication', 'older_function', 'older_pain',\n",
    "        'osteo_manage', 'diabetes_eye', 'diabetes_kidney', 'diabetes_bloodsugar', 'diabetes_chol',\n",
    "        'bloodpressure', 'ra_manage', 'bladder', 'falling', 'readmissions',\n",
    "        'nodelays', 'carequickly', 'customer_service',\n",
    "        'overallrating_care', 'overallrating_plan',\n",
    "        'complaints_plan', 'access_problems', 'leave_plan',\n",
    "        'appeals_timely', 'appeals_review', 'ttyt_available',\n",
    "    ],\n",
    "    2013: [\n",
    "        'contractid', 'org_type', 'contract_name', 'org_marketing', 'org_parent',\n",
    "        'breastcancer_screen', 'rectalcancer_screen', 'cv_cholscreen', 'diab_cholscreen',\n",
    "        'glaucoma_test', 'flu_vaccine',\n",
    "        'physical_health', 'mental_health', 'physical_monitor',\n",
    "        'bmi_assess', 'older_medication', 'older_function', 'older_pain',\n",
    "        'osteo_manage', 'diabetes_eye', 'diabetes_kidney', 'diabetes_bloodsugar', 'diabetes_chol',\n",
    "        'bloodpressure', 'ra_manage', 'bladder', 'falling', 'readmissions',\n",
    "        'nodelays', 'carequickly', 'customer_service',\n",
    "        'overallrating_care', 'overallrating_plan',\n",
    "        'coordination', 'complaints_plan', 'access_problems', 'leave_plan', 'improve',\n",
    "        'appeals_timely', 'appeals_review', 'ttyt_available', 'enroll_timely',\n",
    "    ],\n",
    "    2014: [\n",
    "        'contractid', 'org_type', 'contract_name', 'org_marketing', 'org_parent',\n",
    "        'breastcancer_screen', 'rectalcancer_screen', 'cv_cholscreen', 'diab_cholscreen',\n",
    "        'glaucoma_test', 'flu_vaccine',\n",
    "        'physical_health', 'mental_health', 'physical_monitor',\n",
    "        'bmi_assess', 'older_medication', 'older_function', 'older_pain',\n",
    "        'osteo_manage', 'diabetes_eye', 'diabetes_kidney', 'diabetes_bloodsugar', 'diabetes_chol',\n",
    "        'bloodpressure', 'ra_manage', 'bladder', 'falling', 'readmissions',\n",
    "        'nodelays', 'carequickly', 'customer_service',\n",
    "        'overallrating_care', 'overallrating_plan',\n",
    "        'coordination', 'complaints_plan', 'access_problems', 'leave_plan', 'improve',\n",
    "        'appeals_timely', 'appeals_review', 'ttyt_available',\n",
    "    ],\n",
    "    2015: [\n",
    "        'contractid', 'org_type', 'contract_name', 'org_marketing', 'org_parent',\n",
    "        'rectalcancer_screen', 'cv_cholscreen', 'diab_cholscreen', 'flu_vaccine',\n",
    "        'physical_health', 'mental_health', 'physical_monitor',\n",
    "        'bmi_assess', 'specialneeds_manage',\n",
    "        'older_medication', 'older_function', 'older_pain',\n",
    "        'osteo_manage', 'diabetes_eye', 'diabetes_kidney', 'diabetes_bloodsugar', 'diabetes_chol',\n",
    "        'bloodpressure', 'ra_manage', 'bladder', 'falling', 'readmissions',\n",
    "        'nodelays', 'carequickly', 'customer_service',\n",
    "        'overallrating_care', 'overallrating_plan',\n",
    "        'coordination', 'complaints_plan', 'leave_plan', 'improve',\n",
    "        'appeals_timely', 'appeals_review',\n",
    "    ],\n",
    "}\n",
    "\n",
    "_ID_COLS = {\n",
    "    'contractid', 'org_type', 'contract_name', 'org_marketing',\n",
    "    'org_parent', 'org_name', 'org_marketing_name', 'parent_org',\n",
    "}\n",
    "\n",
    "print('RATING_VARS loaded for years:', sorted(RATING_VARS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb2c19fb-1066-4c69-9872-23336f281018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilities loaded.\n"
     ]
    }
   ],
   "source": [
    "def read_csv_safe(path: Path, **kw) -> pd.DataFrame:\n",
    "    \"\"\"Try utf-8 then latin-1; skip bad lines.\"\"\"\n",
    "    if kw.get('engine') == 'python':\n",
    "        kw.pop('low_memory', None)\n",
    "    else:\n",
    "        kw.setdefault('low_memory', False)\n",
    "    kw.setdefault('on_bad_lines', 'skip')\n",
    "    for enc in ['utf-8', 'latin-1', 'cp1252']:\n",
    "        try:\n",
    "            return pd.read_csv(path, encoding=enc, **kw)\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    return pd.read_csv(path, **kw)\n",
    "\n",
    "\n",
    "_CONTRACT_RE = re.compile(r'^[A-Z]\\d{4,5}$')\n",
    "\n",
    "def probe_data_start(path: Path) -> int:\n",
    "    \"\"\"\n",
    "    Scan the first 25 rows and return the 0-based row index where column 0\n",
    "    first looks like a CMS contract ID (e.g. 'H1234' or 'H12345').\n",
    "    Pass this as skiprows= so row 0 of the resulting DataFrame is real data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = path.read_bytes().decode('latin-1', errors='replace')\n",
    "        for i, line in enumerate(text.splitlines()[:25]):\n",
    "            first = line.split(',')[0].strip().strip('\"').strip(\"'\")\n",
    "            if _CONTRACT_RE.match(first):\n",
    "                return i\n",
    "    except Exception:\n",
    "        pass\n",
    "    return 0\n",
    "\n",
    "\n",
    "def find_file(directory: Path, patterns: list) -> Optional[Path]:\n",
    "    for pat in patterns:\n",
    "        hits = sorted(directory.glob(pat))\n",
    "        if hits:\n",
    "            return hits[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def clean_contractid(s: pd.Series) -> pd.Series:\n",
    "    return s.astype(str).str.strip().str.extract(r'([A-Z]\\d{4,5})', expand=False)\n",
    "\n",
    "\n",
    "def clean_planid(x) -> Optional[str]:\n",
    "    d = re.sub(r'\\D', '', '' if pd.isna(x) else str(x))\n",
    "    return d[-3:].zfill(3) if d else None\n",
    "\n",
    "\n",
    "def clean_fips(x) -> Optional[str]:\n",
    "    d = re.sub(r'\\D', '', '' if pd.isna(x) else str(x))\n",
    "    if not d:\n",
    "        return None\n",
    "    d = d[-5:].zfill(5)\n",
    "    return d if len(d) == 5 else None\n",
    "\n",
    "\n",
    "def clean_ssa(x) -> Optional[str]:\n",
    "    d = re.sub(r'\\D', '', '' if pd.isna(x) else str(x))\n",
    "    if not d:\n",
    "        return None\n",
    "    d = d[-5:].zfill(5)\n",
    "    return d if len(d) == 5 else None\n",
    "\n",
    "\n",
    "def to_float(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Strip commas/asterisks and coerce to float.\"\"\"\n",
    "    t = s.astype(str).str.replace(',', '', regex=False).str.strip()\n",
    "    return pd.to_numeric(t.str.extract(r'(\\d+(?:\\.\\d+)?)', expand=False), errors='coerce')\n",
    "\n",
    "\n",
    "def raw_to_star(raw: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convert a continuous raw domain score to a half-star CMS rating.\n",
    "    Used as a fallback when partc_score is not parseable from the summary file.\n",
    "\n",
    "    Boundaries (right-exclusive):\n",
    "      < 1.25 → 1.0 | 1.25-1.75 → 1.5 | 1.75-2.25 → 2.0 | 2.25-2.75 → 2.5\n",
    "      2.75-3.25 → 3.0 | 3.25-3.75 → 3.5 | 3.75-4.25 → 4.0 | 4.25-4.75 → 4.5\n",
    "      >= 4.75 → 5.0\n",
    "    \"\"\"\n",
    "    bounds = [-np.inf, 1.25, 1.75, 2.25, 2.75, 3.25, 3.75, 4.25, 4.75, np.inf]\n",
    "    labels = [1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5, 5.0]\n",
    "    s = pd.to_numeric(raw, errors='coerce')\n",
    "    return pd.cut(s, bins=bounds, labels=labels, right=False).astype(float)\n",
    "\n",
    "\n",
    "print('Utilities loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ab58b99-2ce1-4377-9a11-d4d89a779bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enrollment functions defined.\n"
     ]
    }
   ],
   "source": [
    "def load_contract_info(year: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Code.\n",
    "    \"\"\"\n",
    "    p = find_file(ENROLL_DIR, [\n",
    "        f'CPSC_Contract_Info_{year}_01.csv',\n",
    "        f'CPSC_Contract_Info_{year}_1.csv',\n",
    "        f'CPSC_Contract_Info_{year}*.csv',\n",
    "    ])\n",
    "    if p is None:\n",
    "        raise FileNotFoundError(f'No contract-info file for {year} in {ENROLL_DIR}')\n",
    "\n",
    "    df = read_csv_safe(p, dtype=str)\n",
    "    df.columns = [\n",
    "        re.sub(r'[^\\w]+', '_', c.strip().lower()).strip('_') for c in df.columns\n",
    "    ]\n",
    "\n",
    "    renames = {\n",
    "        'contract_id': 'contractid', 'contract_number': 'contractid',\n",
    "        'plan_id': 'planid',\n",
    "        'organization_type': 'org_type',\n",
    "        'offers_part_d': 'partd',\n",
    "        'snp_plan': 'snp',\n",
    "        'organization_name': 'org_name',\n",
    "        'organization_marketing_name': 'org_marketing_name',\n",
    "        'parent_organization': 'parent_org',\n",
    "    }\n",
    "    df = df.rename(columns={k: v for k, v in renames.items() if k in df.columns})\n",
    "\n",
    "    df['contractid'] = clean_contractid(df['contractid'])\n",
    "    df['planid']     = df['planid'].apply(clean_planid)\n",
    "    df = df.dropna(subset=['contractid', 'planid'])\n",
    "\n",
    "    if 'snp' in df.columns:\n",
    "        df = df[df['snp'].astype(str).str.strip() == 'No']\n",
    "    planid_n = pd.to_numeric(df['planid'], errors='coerce')\n",
    "    df = df[~planid_n.between(800, 899)]\n",
    "    if 'plan_type' in df.columns:\n",
    "        df = df[~df['plan_type'].astype(str).str.upper().str.contains('PDP', na=False)]\n",
    "\n",
    "    keep = [c for c in ['contractid', 'planid', 'org_type', 'plan_type',\n",
    "                         'partd', 'snp', 'eghp', 'org_name',\n",
    "                         'org_marketing_name', 'plan_name', 'parent_org']\n",
    "            if c in df.columns]\n",
    "    return df[keep].drop_duplicates()\n",
    "\n",
    "\n",
    "def build_plan_county_year(year: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    cache = CACHE_DIR / f'enroll_{year}.csv'\n",
    "    if cache.exists():\n",
    "        out = pd.read_csv(cache, dtype=str)\n",
    "        print(f'  enroll {year}: (cached) {out.shape[0]} rows')\n",
    "        return out\n",
    "\n",
    "    contract    = load_contract_info(year)\n",
    "    month_files = sorted(ENROLL_DIR.glob(f'CPSC_Enrollment_Info_{year}_*.csv'))\n",
    "    if not month_files:\n",
    "        raise FileNotFoundError(f'No enrollment files for {year}')\n",
    "\n",
    "    frames = []\n",
    "    for p in month_files:\n",
    "        m_match = re.search(rf'{year}_(\\d+)\\.csv$', p.name)\n",
    "        if not m_match:\n",
    "            continue\n",
    "        m = int(m_match.group(1))\n",
    "\n",
    "        dfm = read_csv_safe(p, dtype=str)\n",
    "        dfm.columns = [\n",
    "            re.sub(r'[^\\w]+', '_', c.strip().lower()).strip('_') for c in dfm.columns\n",
    "        ]\n",
    "        for old, new in [('contract_number', 'contractid'), ('contract_id', 'contractid'),\n",
    "                          ('plan_id', 'planid'), ('fips_state_county_code', 'fips')]:\n",
    "            if old in dfm.columns and new not in dfm.columns:\n",
    "                dfm = dfm.rename(columns={old: new})\n",
    "\n",
    "        keep = [c for c in ['contractid', 'planid', 'fips', 'state', 'county', 'enrollment']\n",
    "                if c in dfm.columns]\n",
    "        dfm = dfm[keep].copy()\n",
    "        dfm['contractid'] = clean_contractid(dfm['contractid'])\n",
    "        dfm['planid']     = dfm['planid'].apply(clean_planid)\n",
    "        dfm['fips']       = dfm['fips'].apply(clean_fips)\n",
    "        dfm['enrollment'] = pd.to_numeric(\n",
    "            dfm['enrollment'].astype(str).str.replace(',', '', regex=False), errors='coerce')\n",
    "        dfm['month'] = m\n",
    "\n",
    "        \n",
    "        dfm = dfm.merge(contract[['contractid', 'planid']], on=['contractid', 'planid'], how='inner')\n",
    "        frames.append(dfm)\n",
    "\n",
    "    if not frames:\n",
    "        raise RuntimeError(f'No usable enrollment data for {year}')\n",
    "\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "    df = df.dropna(subset=['fips', 'contractid', 'planid'])\n",
    "\n",
    "    \n",
    "    if 'state' in df.columns and 'county' in df.columns:\n",
    "        df = df.sort_values(['state', 'county', 'month'])\n",
    "        df['fips'] = (df.groupby(['state', 'county'])['fips']\n",
    "                        .transform(lambda x: x.ffill().bfill()))\n",
    "\n",
    "    \n",
    "    out = (\n",
    "        df.groupby(['contractid', 'planid', 'fips'], as_index=False)\n",
    "          .agg(n_months=('month', 'count'),\n",
    "               avg_enrollment=('enrollment', 'mean'),\n",
    "               last_enrollment=('enrollment', 'last'))\n",
    "    )\n",
    "\n",
    "    \n",
    "    if 'state' in df.columns:\n",
    "        loc = (\n",
    "            df.dropna(subset=['state', 'county'])\n",
    "              .sort_values('month')\n",
    "              .groupby(['contractid', 'planid', 'fips'], as_index=False)\n",
    "              .last()[['contractid', 'planid', 'fips', 'state', 'county']]\n",
    "        )\n",
    "        out = out.merge(loc, on=['contractid', 'planid', 'fips'], how='left')\n",
    "\n",
    "    out = out.merge(contract, on=['contractid', 'planid'], how='left')\n",
    "    out['year'] = year\n",
    "\n",
    "    out.to_csv(cache, index=False)\n",
    "    months_found = sorted(df['month'].unique().tolist())\n",
    "    print(f'  enroll {year}: {out.shape[0]} rows  months={months_found}')\n",
    "    return out\n",
    "\n",
    "\n",
    "print('Enrollment functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d267de-e5f4-4cb4-bfad-ebda0f05a0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service-area functions defined.\n"
     ]
    }
   ],
   "source": [
    "def load_service_area(year: int) -> pd.DataFrame:\n",
    "    cache = CACHE_DIR / f'sarea_{year}.csv'\n",
    "    if cache.exists():\n",
    "        out = pd.read_csv(cache, dtype=str)\n",
    "        print(f'  sarea  {year}: (cached) {out.shape[0]} rows')\n",
    "        return out\n",
    "\n",
    "    \n",
    "    sa_files = sorted(SAREA_DIR.glob(f'MA_Cnty_SA_{year}_*.csv'))\n",
    "    if not sa_files:\n",
    "        p = find_file(SAREA_DIR, [\n",
    "            f'MA_Cnty_SA_{year}_01.csv', f'MA_Cnty_SA_{year}01.csv',\n",
    "            f'MA_Cnty_SA_{year}.csv', f'*{year}*SA*.csv',\n",
    "        ])\n",
    "        sa_files = [p] if p else []\n",
    "\n",
    "    if not sa_files:\n",
    "        print(f'  sarea  {year}: FILE NOT FOUND — returning empty')\n",
    "        return pd.DataFrame(columns=['contractid', 'fips', 'ssa'])\n",
    "\n",
    "    frames = []\n",
    "    for p in sa_files:\n",
    "        m_match = re.search(rf'{year}_(\\d+)\\.csv$', p.name)\n",
    "        m = int(m_match.group(1)) if m_match else 0\n",
    "\n",
    "        dfm = read_csv_safe(p, dtype=str)\n",
    "        dfm.columns = [\n",
    "            re.sub(r'[^\\w]+', '_', c.strip().lower()).strip('_') for c in dfm.columns\n",
    "        ]\n",
    "        for old, new in [('contract_id', 'contractid'), ('contract', 'contractid'),\n",
    "                          ('fips_state_county_code', 'fips')]:\n",
    "            if old in dfm.columns and new not in dfm.columns:\n",
    "                dfm = dfm.rename(columns={old: new})\n",
    "\n",
    "        dfm['contractid'] = clean_contractid(dfm['contractid'])\n",
    "        dfm['fips']       = dfm['fips'].apply(clean_fips)\n",
    "        if 'ssa' in dfm.columns:\n",
    "            dfm['ssa'] = dfm['ssa'].apply(clean_ssa)\n",
    "        dfm['month'] = m\n",
    "        frames.append(dfm)\n",
    "\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "    df = df.dropna(subset=['contractid', 'fips'])\n",
    "\n",
    "    if 'state' in df.columns and 'county' in df.columns:\n",
    "        df = df.sort_values(['state', 'county', 'month'])\n",
    "        df['fips'] = (df.groupby(['state', 'county'])['fips']\n",
    "                        .transform(lambda x: x.ffill().bfill()))\n",
    "\n",
    "    \n",
    "    out = (\n",
    "        df.sort_values('month')\n",
    "          .groupby(['contractid', 'fips'], as_index=False)\n",
    "          .last()\n",
    "    )\n",
    "    keep = [c for c in ['contractid', 'fips', 'ssa'] if c in out.columns]\n",
    "    out  = out[keep].drop_duplicates(subset=['contractid', 'fips'])\n",
    "\n",
    "    out.to_csv(cache, index=False)\n",
    "    print(f'  sarea  {year}: {out.shape[0]} rows')\n",
    "    return out\n",
    "\n",
    "\n",
    "print('Service-area functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f86c344-3d16-45a6-bbaf-077aa4dbf4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penetration functions defined.\n"
     ]
    }
   ],
   "source": [
    "def load_penetration(year: int) -> pd.DataFrame:\n",
    "    cache = CACHE_DIR / f'pen_{year}.csv'\n",
    "    if cache.exists():\n",
    "        out = pd.read_csv(cache, dtype=str)\n",
    "        print(f'  pen    {year}: (cached) {out.shape[0]} counties')\n",
    "        return out\n",
    "\n",
    "    pen_files = sorted(PEN_DIR.glob(f'State_County_Penetration_MA_{year}_*.csv'))\n",
    "    if not pen_files:\n",
    "        raise FileNotFoundError(f'No penetration files for {year} in {PEN_DIR}')\n",
    "\n",
    "    frames = []\n",
    "    for p in pen_files:\n",
    "        m_match = re.search(rf'{year}_(\\d+)\\.csv$', p.name)\n",
    "        m = int(m_match.group(1)) if m_match else 0\n",
    "\n",
    "        dfm = read_csv_safe(p, dtype=str)\n",
    "        dfm.columns = [\n",
    "            re.sub(r'[^\\w]+', '_', c.strip().lower()).strip('_') for c in dfm.columns\n",
    "        ]\n",
    "        for old, new in [('state_name', 'state'), ('county_name', 'county')]:\n",
    "            if old in dfm.columns:\n",
    "                dfm = dfm.rename(columns={old: new})\n",
    "\n",
    "        keep = [c for c in ['state', 'county', 'fips', 'ssa', 'eligibles', 'enrolled']\n",
    "                if c in dfm.columns]\n",
    "        dfm = dfm[keep].copy()\n",
    "        dfm['fips']      = dfm['fips'].apply(clean_fips)\n",
    "        dfm['ssa']       = dfm['ssa'].apply(clean_ssa)\n",
    "        dfm['eligibles'] = pd.to_numeric(\n",
    "            dfm['eligibles'].astype(str).str.replace(',', '', regex=False), errors='coerce')\n",
    "        dfm['enrolled']  = pd.to_numeric(\n",
    "            dfm['enrolled'].astype(str).str.replace(',', '', regex=False), errors='coerce')\n",
    "        dfm['month'] = m\n",
    "        frames.append(dfm)\n",
    "\n",
    "    df = pd.concat(frames, ignore_index=True)\n",
    "    df = df.dropna(subset=['fips'])\n",
    "\n",
    "    if 'state' in df.columns and 'county' in df.columns:\n",
    "        df = df.sort_values(['state', 'county', 'month'])\n",
    "        df['fips'] = (df.groupby(['state', 'county'])['fips']\n",
    "                        .transform(lambda x: x.ffill().bfill()))\n",
    "\n",
    "    \n",
    "    out = (\n",
    "        df.groupby('fips', as_index=False)\n",
    "          .agg(avg_eligibles=('eligibles', 'mean'),\n",
    "               avg_enrolled=('enrolled', 'mean'),\n",
    "               ssa=('ssa', 'last'))\n",
    "    )\n",
    "\n",
    "    \n",
    "    fips_counts = out['fips'].value_counts()\n",
    "    out = out[out['fips'].isin(fips_counts[fips_counts == 1].index)].copy()\n",
    "\n",
    "    out['year'] = year\n",
    "    out.to_csv(cache, index=False)\n",
    "    print(f'  pen    {year}: {out.shape[0]} counties')\n",
    "    return out\n",
    "\n",
    "\n",
    "print('Penetration functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "339fa6a8-27dd-4010-ad07-b379bbe1e221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star-ratings functions defined.\n",
      "Year → directory mapping:\n",
      "  2010: 2010  (exists)\n",
      "  2011: 2011  (exists)\n",
      "  2012: Part C 2012 Fall  (exists)\n",
      "  2013: Part C 2013 Fall  (exists)\n",
      "  2014: Part C 2014 Fall  (exists)\n",
      "  2015: 2015 Fall  (exists)\n"
     ]
    }
   ],
   "source": [
    "STAR_YEAR_DIRS = {\n",
    "    2010: STARS_DIR / '2010',\n",
    "    2011: STARS_DIR / '2011',\n",
    "    2012: STARS_DIR / 'Part C 2012 Fall',\n",
    "    2013: STARS_DIR / 'Part C 2013 Fall',\n",
    "    2014: STARS_DIR / 'Part C 2014 Fall',\n",
    "    2015: STARS_DIR / '2015 Fall',\n",
    "}\n",
    "\n",
    "\n",
    "def find_star_files(year: int):\n",
    "    \"\"\"\n",
    "    Return (domain_path, summary_path) for a given year.\n",
    "\n",
    "    For 2010-2011: files contain 'domain' / 'summary' in their names.\n",
    "    For 2012-2015: files live in 'Part C YYYY Fall' or 'YYYY Fall' folders;\n",
    "                   pick by column count (domain file has far more columns).\n",
    "    \"\"\"\n",
    "    year_dir = STAR_YEAR_DIRS.get(year)\n",
    "    if year_dir is None or not year_dir.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f'Star-rating directory for {year} not found.\\n'\n",
    "            f'Expected: {year_dir}\\n'\n",
    "            f'Contents of STARS_DIR: {[p.name for p in sorted(STARS_DIR.iterdir())]}'\n",
    "        )\n",
    "\n",
    "    all_csvs = sorted(year_dir.glob('*.csv'))\n",
    "    if not all_csvs:\n",
    "        raise FileNotFoundError(\n",
    "            f'No CSVs in {year_dir}.\\n'\n",
    "            f'Contents: {[p.name for p in sorted(year_dir.iterdir())]}'\n",
    "        )\n",
    "\n",
    "    \n",
    "    dom  = find_file(year_dir, [f'*[Dd]omain*.csv'])\n",
    "    summ = find_file(year_dir, [f'*[Ss]ummary*.csv'])\n",
    "\n",
    "    if dom is None or summ is None:\n",
    "        def col_count(p):\n",
    "            try:\n",
    "                skip = probe_data_start(p)\n",
    "                lines = p.read_bytes().decode('latin-1', errors='replace').splitlines()\n",
    "                if skip < len(lines):\n",
    "                    return len(lines[skip].split(','))\n",
    "                return 0\n",
    "            except Exception:\n",
    "                return 0\n",
    "\n",
    "        sized = sorted([(col_count(p), p) for p in all_csvs], reverse=True)\n",
    "        \n",
    "        if dom  is None: dom  = sized[0][1]  if len(sized) >= 1 else None\n",
    "        if summ is None: summ = sized[-1][1] if len(sized) >= 2 else dom\n",
    "\n",
    "    if dom  is None: raise FileNotFoundError(f'Cannot find domain file for {year} in {year_dir}')\n",
    "    if summ is None: raise FileNotFoundError(f'Cannot find summary file for {year} in {year_dir}')\n",
    "\n",
    "    return dom, summ\n",
    "\n",
    "\n",
    "def _load_domain(year: int, path: Path) -> pd.DataFrame:\n",
    "    skip      = probe_data_start(path)\n",
    "    col_names = RATING_VARS[year]\n",
    "\n",
    "    df = read_csv_safe(path, skiprows=skip, header=None, dtype=str, on_bad_lines='skip')\n",
    "\n",
    "    n     = df.shape[1]\n",
    "    names = col_names[:n] + [f'_x{i}' for i in range(len(col_names), n)]\n",
    "    df.columns = names\n",
    "\n",
    "    df['contractid'] = clean_contractid(df['contractid'])\n",
    "    df = df.dropna(subset=['contractid'])\n",
    "\n",
    "    measure_cols = [c for c in col_names if c not in _ID_COLS and c in df.columns]\n",
    "    for c in measure_cols:\n",
    "        df[c] = to_float(df[c])\n",
    "\n",
    "    df['raw_score'] = df[measure_cols].mean(axis=1, skipna=True)\n",
    "    return df[['contractid', 'raw_score']].drop_duplicates(subset='contractid')\n",
    "\n",
    "\n",
    "_NEW_FLAG = re.compile(r'too new|new to rate|plan too new', re.IGNORECASE)\n",
    "\n",
    "def _load_summary(year: int, path: Path) -> pd.DataFrame:\n",
    "    skip = probe_data_start(path)\n",
    "    df   = read_csv_safe(path, skiprows=skip, header=None, dtype=str, on_bad_lines='skip')\n",
    "\n",
    "    base = ['contractid', 'org_type', 'contract_name', 'org_marketing', 'partc_score']\n",
    "    n    = df.shape[1]\n",
    "    df.columns = base[:n] + [f'col_{i}' for i in range(5, n)]\n",
    "\n",
    "    df['contractid'] = clean_contractid(df['contractid'])\n",
    "    df = df.dropna(subset=['contractid'])\n",
    "\n",
    "    \n",
    "    is_new = df['partc_score'].astype(str).str.contains(_NEW_FLAG, na=False)\n",
    "    df['new_contract'] = is_new.astype(int)\n",
    "    df['partc_score']  = to_float(df['partc_score'])\n",
    "    df.loc[df['new_contract'] == 1, 'partc_score'] = np.nan\n",
    "\n",
    "    \n",
    "    df['partcd_score'] = np.nan\n",
    "    if 'col_5' in df.columns:\n",
    "        cand    = to_float(df['col_5'])\n",
    "        valid_n = int(cand.notna().sum())\n",
    "        if valid_n > 20 and float(((cand >= 1) & (cand <= 5)).sum() / valid_n) > 0.50:\n",
    "            df['partcd_score'] = cand\n",
    "\n",
    "    df.loc[df['new_contract'] == 1, 'partcd_score'] = np.nan\n",
    "\n",
    "    return (\n",
    "        df[['contractid', 'partc_score', 'partcd_score', 'new_contract']]\n",
    "        .drop_duplicates(subset='contractid')\n",
    "    )\n",
    "\n",
    "\n",
    "def load_star_ratings(year: int) -> pd.DataFrame:\n",
    "    cache = CACHE_DIR / f'stars_{year}.csv'\n",
    "    if cache.exists():\n",
    "        out = pd.read_csv(cache, dtype=str)\n",
    "        pc  = pd.to_numeric(out['partc_score'], errors='coerce')\n",
    "        rs  = pd.to_numeric(out['raw_score'],   errors='coerce')\n",
    "        print(f'  stars  {year}: (cached)  partc={pc.notna().sum()}  raw={rs.notna().sum()}')\n",
    "        return out\n",
    "\n",
    "    dom_path, sum_path = find_star_files(year)\n",
    "    print(f'  stars  {year}: domain  = {dom_path.name}')\n",
    "    print(f'           summary = {sum_path.name}')\n",
    "\n",
    "    domain  = _load_domain(year,  dom_path)\n",
    "    summary = _load_summary(year, sum_path)\n",
    "\n",
    "    out = domain.merge(summary, on='contractid', how='outer')\n",
    "    out['new_contract'] = out['new_contract'].fillna(0).astype(int)\n",
    "    out['year'] = year\n",
    "\n",
    "   \n",
    "    pc = pd.to_numeric(out['partc_score'], errors='coerce')\n",
    "    if pc.notna().sum() == 0:\n",
    "        rs = pd.to_numeric(out['raw_score'], errors='coerce')\n",
    "        out['partc_score'] = raw_to_star(rs)\n",
    "        print(f'    INFO: partc_score for {year} derived from raw_score via CMS rounding')\n",
    "\n",
    "    for col in ['partc_score', 'partcd_score', 'raw_score']:\n",
    "        if col in out.columns:\n",
    "            out.loc[out['new_contract'] == 1, col] = np.nan\n",
    "\n",
    "    n_pc  = int(pd.to_numeric(out['partc_score'], errors='coerce').notna().sum())\n",
    "    n_raw = int(pd.to_numeric(out['raw_score'],   errors='coerce').notna().sum())\n",
    "    print(f'           contracts={out.shape[0]}  partc_nonmiss={n_pc}  raw_nonmiss={n_raw}')\n",
    "\n",
    "    out.to_csv(cache, index=False)\n",
    "    return out\n",
    "\n",
    "\n",
    "print('Star-ratings functions defined.')\n",
    "print('Year → directory mapping:')\n",
    "for y, d in STAR_YEAR_DIRS.items():\n",
    "    print(f'  {y}: {d.name}  ({\"exists\" if d.exists() else \"MISSING\"})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12ec2679-70ac-4cd2-8db7-2278f1da5211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark functions defined.\n"
     ]
    }
   ],
   "source": [
    "_BENCH_COLS = [\n",
    "    'ssa', 'state', 'county_name',\n",
    "    'aged_parta', 'aged_partb',\n",
    "    'disabled_parta', 'disabled_partb',\n",
    "    'esrd_ab', 'risk_ab',\n",
    "]\n",
    "\n",
    "\n",
    "def load_benchmark(year: int) -> pd.DataFrame:\n",
    "    cache = CACHE_DIR / f'bench_{year}.csv'\n",
    "    if cache.exists():\n",
    "        out = pd.read_csv(cache, dtype=str)\n",
    "        print(f'  bench  {year}: (cached) {out.shape[0]} rows')\n",
    "        return out\n",
    "\n",
    "    p = find_file(BENCH_DIR, [\n",
    "        f'ratebook{year}/CountyRate{year}.csv',\n",
    "        f'ratebook{year}/countyrate{year}.csv',\n",
    "        f'CountyRate{year}.csv',\n",
    "        f'*{year}*.csv',\n",
    "    ])\n",
    "    if p is None:\n",
    "        print(f'  bench  {year}: FILE NOT FOUND')\n",
    "        return pd.DataFrame(columns=['ssa', 'risk_ab', 'aged_parta', 'aged_partb', 'year'])\n",
    "\n",
    "    skip = probe_data_start(p)\n",
    "\n",
    "    df = read_csv_safe(p, skiprows=skip, header=None, dtype=str, on_bad_lines='skip')\n",
    "\n",
    "    n  = df.shape[1]\n",
    "    df.columns = _BENCH_COLS[:n] + [f'_b{i}' for i in range(len(_BENCH_COLS), n)]\n",
    "\n",
    "    df['ssa']        = df['ssa'].apply(clean_ssa)\n",
    "    df['risk_ab']    = to_float(df['risk_ab'])    if 'risk_ab'    in df.columns else np.nan\n",
    "    df['aged_parta'] = to_float(df['aged_parta']) if 'aged_parta' in df.columns else np.nan\n",
    "    df['aged_partb'] = to_float(df['aged_partb']) if 'aged_partb' in df.columns else np.nan\n",
    "\n",
    "    out = (\n",
    "        df[['ssa', 'risk_ab', 'aged_parta', 'aged_partb']]\n",
    "        .dropna(subset=['ssa'])\n",
    "        .drop_duplicates(subset='ssa')\n",
    "        .copy()\n",
    "    )\n",
    "    out['year'] = year\n",
    "\n",
    "    out.to_csv(cache, index=False)\n",
    "    print(f'  bench  {year}: {out.shape[0]} rows  (skip={skip})')\n",
    "    return out\n",
    "\n",
    "\n",
    "print('Benchmark functions defined.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7efd0c41-a14c-4ba3-98b4-14fc8efb19f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "YEAR 2010\n",
      "  enroll 2010: (cached) 675013 rows\n",
      "  sarea  2010: (cached) 435122 rows\n",
      "  pen    2010: (cached) 3280 counties\n",
      "  stars  2010: (cached)  partc=367  raw=537\n",
      "  bench  2010: (cached) 4 rows\n",
      "  FINAL rows       = 109948\n",
      "  Star_Rating ≠ NA = 60519\n",
      "  raw_score   ≠ NA = 95248\n",
      "  mkt_share   ≠ NA = 30662\n",
      "\n",
      "============================================================\n",
      "YEAR 2011\n",
      "  enroll 2011: (cached) 507548 rows\n",
      "  sarea  2011: (cached) 380785 rows\n",
      "  pen    2011: (cached) 3228 counties\n",
      "  stars  2011: (cached)  partc=507  raw=507\n",
      "  bench  2011: (cached) 5 rows\n",
      "  FINAL rows       = 67967\n",
      "  Star_Rating ≠ NA = 57318\n",
      "  raw_score   ≠ NA = 57318\n",
      "  mkt_share   ≠ NA = 24200\n",
      "\n",
      "============================================================\n",
      "YEAR 2012\n",
      "  enroll 2012: (cached) 498019 rows\n",
      "  sarea  2012: (cached) 374145 rows\n",
      "  pen    2012: (cached) 3224 counties\n",
      "  stars  2012: domain  = 2012_Part_C_Report_Card_Master_Table_2011_11_01_Domain.csv\n",
      "           summary = 2012_Part_C_Report_Card_Master_Table_2011_11_01_Summary.csv\n",
      "           contracts=569  partc_nonmiss=446  raw_nonmiss=484\n",
      "  bench  2012: 2 rows  (skip=0)\n",
      "  FINAL rows       = 67212\n",
      "  Star_Rating ≠ NA = 58518\n",
      "  raw_score   ≠ NA = 59512\n",
      "  mkt_share   ≠ NA = 24294\n",
      "\n",
      "============================================================\n",
      "YEAR 2013\n",
      "  enroll 2013: 488390 rows  months=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  sarea  2013: 376589 rows\n",
      "  pen    2013: 3224 counties\n",
      "  stars  2013: domain  = 2013_Part_C_Report_Card_Master_Table_2012_10_17_Domain.csv\n",
      "           summary = 2013_Part_C_Report_Card_Master_Table_2012_10_17_Summary.csv\n",
      "           contracts=578  partc_nonmiss=10  raw_nonmiss=472\n",
      "  bench  2013: 3248 rows  (skip=0)\n",
      "  FINAL rows       = 67789\n",
      "  Star_Rating ≠ NA = 50536\n",
      "  raw_score   ≠ NA = 65076\n",
      "  mkt_share   ≠ NA = 25213\n",
      "\n",
      "============================================================\n",
      "YEAR 2014\n",
      "  enroll 2014: 506498 rows  months=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  sarea  2014: 397122 rows\n",
      "  pen    2014: 3224 counties\n",
      "  stars  2014: domain  = 2014_Part_C_Report_Card_Master_Table_2013_10_17_domain.csv\n",
      "           summary = 2014_Part_C_Report_Card_Master_Table_2013_10_17_summary.csv\n",
      "           contracts=677  partc_nonmiss=11  raw_nonmiss=457\n",
      "  bench  2014: 1 rows  (skip=0)\n",
      "  FINAL rows       = 62333\n",
      "  Star_Rating ≠ NA = 391\n",
      "  raw_score   ≠ NA = 59557\n",
      "  mkt_share   ≠ NA = 24629\n",
      "\n",
      "============================================================\n",
      "YEAR 2015\n",
      "  enroll 2015: 470935 rows  months=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "  sarea  2015: 377723 rows\n",
      "  pen    2015: 3224 counties\n",
      "  stars  2015: domain  = 2015_Report_Card_Master_Table_2014_10_03_domain.csv\n",
      "           summary = 2015_Report_Card_Master_Table_2014_10_03_summary.csv\n",
      "           contracts=691  partc_nonmiss=9  raw_nonmiss=517\n",
      "  bench  2015: FILE NOT FOUND\n",
      "  FINAL rows       = 65491\n",
      "  Star_Rating ≠ NA = 311\n",
      "  raw_score   ≠ NA = 61730\n",
      "  mkt_share   ≠ NA = 24850\n"
     ]
    }
   ],
   "source": [
    "all_years = []\n",
    "\n",
    "for year in YEARS:\n",
    "    print(f'\\n{\"=\"*60}\\nYEAR {year}')\n",
    "\n",
    "    enroll = build_plan_county_year(year)\n",
    "    sa     = load_service_area(year)\n",
    "    pen    = load_penetration(year)\n",
    "    stars  = load_star_ratings(year)\n",
    "    bench  = load_benchmark(year)\n",
    "\n",
    "    \n",
    "    df = enroll.merge(\n",
    "        sa[['contractid', 'fips']].drop_duplicates(),\n",
    "        on=['contractid', 'fips'], how='inner',\n",
    "    )\n",
    "\n",
    "   \n",
    "    if 'state' in df.columns:\n",
    "        df = df[~df['state'].isin(TERRITORIES)]\n",
    "        df = df[df['state'].astype(str).str.strip() != '']\n",
    "\n",
    "    \n",
    "    if 'snp' in df.columns:\n",
    "        df = df[df['snp'].astype(str).str.strip() == 'No']\n",
    "\n",
    "    planid_n = pd.to_numeric(df['planid'], errors='coerce')\n",
    "    df = df[~planid_n.between(800, 899)]\n",
    "    df = df.dropna(subset=['planid', 'fips'])\n",
    "\n",
    "    \n",
    "    pen_merge = pen[['fips', 'avg_eligibles', 'avg_enrolled', 'ssa']].drop_duplicates('fips')\n",
    "    df = df.merge(pen_merge, on='fips', how='left', suffixes=('_sa', '_pen'))\n",
    "\n",
    "    \n",
    "    if 'ssa_sa' in df.columns and 'ssa_pen' in df.columns:\n",
    "        df['ssa'] = df['ssa_sa'].where(df['ssa_sa'].notna(), df['ssa_pen'])\n",
    "        df.drop(columns=['ssa_sa', 'ssa_pen'], inplace=True)\n",
    "    elif 'ssa_sa' in df.columns:\n",
    "        df.rename(columns={'ssa_sa': 'ssa'}, inplace=True)\n",
    "    elif 'ssa_pen' in df.columns:\n",
    "        df.rename(columns={'ssa_pen': 'ssa'}, inplace=True)\n",
    "\n",
    "    \n",
    "    star_cols = [c for c in ['contractid', 'partc_score', 'partcd_score',\n",
    "                              'raw_score', 'new_contract'] if c in stars.columns]\n",
    "    df = df.merge(stars[star_cols], on='contractid', how='left')\n",
    "\n",
    "    for c in ['partc_score', 'partcd_score', 'raw_score']:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "   \n",
    "    partd_col = df.get('partd', pd.Series(['No'] * len(df), index=df.index))\n",
    "    partd_no  = partd_col.astype(str).str.strip() == 'No'\n",
    "\n",
    "    pc  = df['partc_score']  if 'partc_score'  in df.columns else pd.Series(np.nan, index=df.index)\n",
    "    pcd = df['partcd_score'] if 'partcd_score' in df.columns else pd.Series(np.nan, index=df.index)\n",
    "\n",
    "    df['Star_Rating'] = np.where(partd_no, pc, np.where(pcd.notna(), pcd, pc))\n",
    "\n",
    "    \n",
    "    bench_cols = [c for c in ['ssa', 'risk_ab', 'aged_parta', 'aged_partb']\n",
    "                  if c in bench.columns]\n",
    "    df = df.merge(\n",
    "        bench[bench_cols].dropna(subset=['ssa']).drop_duplicates('ssa'),\n",
    "        on='ssa', how='left',\n",
    "    )\n",
    "\n",
    "    \n",
    "    for c in ['avg_enrollment', 'last_enrollment', 'avg_enrolled', 'avg_eligibles', 'risk_ab']:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    \n",
    "    df['enrollment_used'] = df.get('last_enrollment', pd.Series(np.nan, index=df.index))\n",
    "    df['enrollment_used'] = df['enrollment_used'].where(\n",
    "        df['enrollment_used'].notna(),\n",
    "        df.get('avg_enrollment', pd.Series(np.nan, index=df.index))\n",
    "    )\n",
    "\n",
    "    \n",
    "    df['mkt_share'] = df['enrollment_used'] / df['avg_enrolled']\n",
    "    invalid = ~np.isfinite(df['mkt_share'].astype(float, errors='ignore'))\n",
    "    df.loc[invalid, 'mkt_share'] = np.nan\n",
    "\n",
    "    \n",
    "    df['ma_rate'] = df.get('risk_ab', pd.Series(np.nan, index=df.index))\n",
    "\n",
    "    df['hmo']       = df.get('plan_type', '').astype(str).str.upper().str.contains('HMO').astype(int)\n",
    "    df['partd_ind'] = (~partd_no).astype(int)\n",
    "    df['plan_key']  = df['contractid'].astype(str) + '-' + df['planid'].astype(str)\n",
    "    df['year']      = year\n",
    "\n",
    "    \n",
    "    keep = [\n",
    "        'year', 'contractid', 'planid', 'plan_key',\n",
    "        'fips', 'state', 'county',\n",
    "        'enrollment_used', 'avg_enrollment', 'last_enrollment',\n",
    "        'avg_enrolled', 'avg_eligibles', 'mkt_share',\n",
    "        'Star_Rating', 'raw_score', 'new_contract',\n",
    "        'partd', 'partd_ind', 'plan_type', 'hmo', 'org_type',\n",
    "        'ssa', 'risk_ab', 'aged_parta', 'aged_partb', 'ma_rate',\n",
    "    ]\n",
    "    keep = [c for c in keep if c in df.columns]\n",
    "    df   = df[keep].copy()\n",
    "\n",
    "    for c in ['Star_Rating', 'raw_score', 'mkt_share', 'enrollment_used',\n",
    "               'avg_enrollment', 'last_enrollment', 'avg_enrolled',\n",
    "               'avg_eligibles', 'risk_ab', 'ma_rate']:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_numeric(df[c], errors='coerce')\n",
    "\n",
    "    all_years.append(df)\n",
    "\n",
    "    print(f'  FINAL rows       = {df.shape[0]}')\n",
    "    print(f'  Star_Rating ≠ NA = {int(df[\"Star_Rating\"].notna().sum())}')\n",
    "    print(f'  raw_score   ≠ NA = {int(df[\"raw_score\"].notna().sum())}')\n",
    "    print(f'  mkt_share   ≠ NA = {int(df[\"mkt_share\"].notna().sum())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc66f126-8e30-4e50-9db7-80ced5470f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files written:\n",
      "  ma_data_2010_2015.csv  (440,740 rows)\n",
      "  ma_data_2010.csv  (109,948 rows)\n",
      "  contract_ratings_2010_2015.csv  (3,504 rows)\n",
      "  plan_year_2010_2015.csv  (13,555 rows)\n"
     ]
    }
   ],
   "source": [
    "ma_data = pd.concat(all_years, ignore_index=True)\n",
    "\n",
    "out_panel = OUTPUT_DIR / 'ma_data_2010_2015.csv'\n",
    "ma_data.to_csv(out_panel, index=False)\n",
    "\n",
    "out_2010 = OUTPUT_DIR / 'ma_data_2010.csv'\n",
    "ma_data[ma_data['year'] == 2010].to_csv(out_2010, index=False)\n",
    "\n",
    "contract_ratings = (\n",
    "    ma_data\n",
    "    .drop_duplicates(subset=['year', 'contractid'])\n",
    "    [['year', 'contractid', 'Star_Rating', 'raw_score', 'new_contract',\n",
    "      'org_type', 'partd_ind', 'hmo']]\n",
    "    .copy()\n",
    ")\n",
    "out_cr = OUTPUT_DIR / 'contract_ratings_2010_2015.csv'\n",
    "contract_ratings.to_csv(out_cr, index=False)\n",
    "\n",
    "plan_year = (\n",
    "    ma_data\n",
    "    .groupby(['year', 'contractid', 'planid'], as_index=False)\n",
    "    .agg(\n",
    "        total_enrollment=('enrollment_used', 'sum'),\n",
    "        Star_Rating=('Star_Rating', 'first'),\n",
    "        raw_score=('raw_score', 'first'),\n",
    "        mkt_share=('mkt_share', 'mean'),\n",
    "        hmo=('hmo', 'first'),\n",
    "        partd_ind=('partd_ind', 'first'),\n",
    "        org_type=('org_type', 'first'),\n",
    "    )\n",
    ")\n",
    "out_py = OUTPUT_DIR / 'plan_year_2010_2015.csv'\n",
    "plan_year.to_csv(out_py, index=False)\n",
    "\n",
    "print('Files written:')\n",
    "for f in [out_panel, out_2010, out_cr, out_py]:\n",
    "    n = pd.read_csv(f).shape[0]\n",
    "    print(f'  {f.name}  ({n:,} rows)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e6bc8f4-c364-4a0a-bca1-ed4b01cf552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Row counts by year ===\n",
      "year\n",
      "2010    109948\n",
      "2011     67967\n",
      "2012     67212\n",
      "2013     67789\n",
      "2014     62333\n",
      "2015     65491\n",
      "\n",
      "=== Star_Rating non-missing by year ===\n",
      "year\n",
      "2010    60519\n",
      "2011    57318\n",
      "2012    58518\n",
      "2013    50536\n",
      "2014      391\n",
      "2015      311\n",
      "\n",
      "=== raw_score non-missing by year ===\n",
      "year\n",
      "2010    95248\n",
      "2011    57318\n",
      "2012    59512\n",
      "2013    65076\n",
      "2014    59557\n",
      "2015    61730\n",
      "\n",
      "=== Star_Rating distribution (plan-county rows) ===\n",
      "Star_Rating  1.0  2.0    2.5    3.0    3.5    4.0   4.5   5.0\n",
      "year                                                         \n",
      "2010           0  475  32422  10162   8262   6224  2869   105\n",
      "2011           0  268   9070  20679  11495  10679  4784   343\n",
      "2012           0  154   8208  20545  13040   7158  7323  2090\n",
      "2013         107  160   4054  10449  19097   9791  3723  3155\n",
      "2014         391    0      0      0      0      0     0     0\n",
      "2015         311    0      0      0      0      0     0     0\n",
      "\n",
      "=== Market-share summary by year ===\n",
      "        count    mean     std  min     25%     50%     75%     max\n",
      "year                                                              \n",
      "2010  30662.0  0.0669  0.1013  0.0  0.0083  0.0271  0.0787  1.0367\n",
      "2011  24200.0  0.0879  0.1278  0.0  0.0108  0.0359  0.1056  0.9536\n",
      "2012  24294.0  0.0875  0.1299  0.0  0.0101  0.0350  0.1053  1.2724\n",
      "2013  25213.0  0.0831  0.1269  0.0  0.0100  0.0330  0.0976  0.9730\n",
      "2014  24629.0  0.0812  0.1248  0.0  0.0100  0.0327  0.0963  1.1267\n",
      "2015  24850.0  0.0796  0.1222  0.0  0.0099  0.0327  0.0949  1.0261\n",
      "\n",
      "=== 2010 contract-level checks (RD analysis) ===\n",
      "  unique contracts         : 580\n",
      "  Star_Rating non-missing  : 313\n",
      "  raw_score   non-missing  : 420\n",
      "  raw_score range          : [1.667, 5.000]\n",
      "\n",
      "Dataset build complete.\n"
     ]
    }
   ],
   "source": [
    "print('=== Row counts by year ===')\n",
    "print(ma_data.groupby('year').size().rename('n_rows').to_string())\n",
    "\n",
    "print('\\n=== Star_Rating non-missing by year ===')\n",
    "print(ma_data.groupby('year')['Star_Rating']\n",
    "             .apply(lambda x: x.notna().sum()).rename('n_star').to_string())\n",
    "\n",
    "print('\\n=== raw_score non-missing by year ===')\n",
    "print(ma_data.groupby('year')['raw_score']\n",
    "             .apply(lambda x: x.notna().sum()).rename('n_raw').to_string())\n",
    "\n",
    "print('\\n=== Star_Rating distribution (plan-county rows) ===')\n",
    "dist = (\n",
    "    ma_data.dropna(subset=['Star_Rating'])\n",
    "           .groupby(['year', 'Star_Rating'])\n",
    "           .size()\n",
    "           .unstack('Star_Rating')\n",
    "           .fillna(0).astype(int)\n",
    ")\n",
    "print(dist.to_string())\n",
    "\n",
    "print('\\n=== Market-share summary by year ===')\n",
    "print(ma_data.groupby('year')['mkt_share'].describe().round(4).to_string())\n",
    "\n",
    "print('\\n=== 2010 contract-level checks (RD analysis) ===')\n",
    "d10   = ma_data[ma_data['year'] == 2010]\n",
    "d10_c = d10.drop_duplicates('contractid')\n",
    "print(f'  unique contracts         : {d10_c.shape[0]}')\n",
    "print(f'  Star_Rating non-missing  : {int(d10_c[\"Star_Rating\"].notna().sum())}')\n",
    "print(f'  raw_score   non-missing  : {int(d10_c[\"raw_score\"].notna().sum())}')\n",
    "if d10_c['raw_score'].notna().any():\n",
    "    lo = d10_c['raw_score'].min()\n",
    "    hi = d10_c['raw_score'].max()\n",
    "    print(f'  raw_score range          : [{lo:.3f}, {hi:.3f}]')\n",
    "\n",
    "print('\\nDataset build complete.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (econ470)",
   "language": "python",
   "name": "econ470-a0kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
